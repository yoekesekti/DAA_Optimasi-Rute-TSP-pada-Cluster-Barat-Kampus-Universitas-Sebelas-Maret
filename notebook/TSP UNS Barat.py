# -*- coding: utf-8 -*-
"""Oret oretan

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wBiPv_9e0p8Uulhj8BqXn4-U7UD4y04X

# **Optimasi Rute TSP pada Cluster Barat Kampus Universitas Sebelas Maret Menggunakan Backtracking dan Branch and Bound**

# **Import & Config**
"""

import time, math, heapq, os, re, platform, subprocess, gc
from copy import deepcopy
import numpy as np
import pandas as pd
import psutil
import matplotlib.pyplot as plt

REPEATS = 10
BASE_SEED = 12345

sizes_to_test = [8, 10, 12, 15]
max_backtracking_n = 10
time_limit_per_run = 60
BT_NODE_LIMIT = 10_000_000

def set_seed(seed: int):
    import random
    random.seed(seed)
    np.random.seed(seed)

def summarize(values):
    """mean, std, ci95_low, ci95_high"""
    from statistics import mean, stdev
    m = mean(values)
    s = stdev(values) if len(values) > 1 else 0.0
    ci = 1.96 * (s / (len(values) ** 0.5)) if len(values) > 1 else 0.0
    return m, s, m - ci, m + ci

import platform
import psutil
import subprocess

print("=== Hardware Specifications ===")

print(f"OS: {platform.system()} {platform.release()} ({platform.version()})")

print(f"CPU: {platform.processor()} ({psutil.cpu_count(logical=False)} physical cores, {psutil.cpu_count(logical=True)} logical cores)")

mem = psutil.virtual_memory()
print(f"RAM: {mem.total / (1024**3):.2f} GB total, {mem.available / (1024**3):.2f} GB available")

try:
    if platform.system() == "Linux":
        gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total,memory.free,memory.used', '--format=csv,noheader']).decode('utf-8').strip()
        if gpu_info:
            print(f"GPU: {gpu_info}")
        else:
            print("GPU: Not detected (or nvidia-smi not found)")
    else:
        print("GPU: Information only available for Linux systems with nvidia-smi.")
except (subprocess.CalledProcessError, FileNotFoundError):
    print("GPU: Not detected (or nvidia-smi not found)")

print("===============================")

"""# **Upload & Load CSV**"""

from google.colab import files

print("Silakan upload file CSV Anda...")
uploaded = files.upload()

filename = list(uploaded.keys())[0]
print(f"File '{filename}' berhasil diupload.")

df = pd.read_csv(filename)
df.head()

"""# **Validasi Kolom + Clean + Ambil Koordinat**"""

# Normalisasi nama kolom (strip spasi)
df = df.rename(columns={c: c.strip() for c in df.columns})

required_cols = {"id", "nama_tempat", "latitude", "longitude"}
if not required_cols.issubset(set(df.columns)):
    raise ValueError(
        f"CSV harus mengandung kolom: {required_cols}. "
        f"Ditemukan: {df.columns.tolist()}"
    )

df = df[['id', 'nama_tempat', 'latitude', 'longitude']].copy()

# Validasi nilai lat/lon
df = df.dropna(subset=["latitude", "longitude"])
df = df[
    (df["latitude"].between(-90, 90)) &
    (df["longitude"].between(-180, 180))
].copy()

# Opsional: hapus duplikat titik
df = df.drop_duplicates(
    subset=["latitude", "longitude"]
).reset_index(drop=True)

names_all = df["nama_tempat"].tolist()
coords_all = list(zip(df["latitude"], df["longitude"]))
N_ALL = len(coords_all)

dist_matrix = build_dist_matrix(coords_all)

print(f"Berhasil load {N_ALL} node dari dataset.")
display(df.head(10))

"""# **Haversine + Distance Matrix Builder**"""

def haversine(lat1, lon1, lat2, lon2):
    R = 6371.0  # km
    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = math.sin(dlat/2)**2 + math.cos(lat1)*math.cos(lat2)*math.sin(dlon/2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    return R * c * 1000  # meter

def build_dist_matrix(coords):
    n = len(coords)
    dist = np.zeros((n, n), dtype=float)
    for i in range(n):
        for j in range(n):
            if i == j:
                dist[i, j] = np.inf
            else:
                dist[i, j] = haversine(coords[i][0], coords[i][1], coords[j][0], coords[j][1])
    return dist

print("Distance Matrix dengan Nama Tempat:")
df_dist = pd.DataFrame(dist_matrix, index=names_all, columns=names_all)
df_dist.index.name = 'From'
df_dist.columns.name = 'To'
display(df_dist)

"""# **Reduce Matrix**"""

def reduce_matrix(mat):
    m = mat.copy()
    n = m.shape[0]
    reduction_cost = 0.0

    # reduce row
    for i in range(n):
        row = m[i]
        finite = row[np.isfinite(row)]
        if finite.size:
            min_val = finite.min()
            if min_val > 0:
                reduction_cost += min_val
                m[i, np.isfinite(m[i])] -= min_val

    # reduce col
    for j in range(n):
        col = m[:, j]
        finite = col[np.isfinite(col)]
        if finite.size:
            min_val = finite.min()
            if min_val > 0:
                reduction_cost += min_val
                m[np.isfinite(m[:, j]), j] -= min_val

    return m, reduction_cost

"""Reduksi matriks digunakan dalam algoritma Branch and Bound untuk menghitung nilai lower bound (batas bawah) dari suatu partial solution. Proses reduksi dilakukan dengan mengurangkan nilai minimum dari setiap baris dan kolom matriks jarak. Nilai pengurangan ini dijumlahkan menjadi reduction cost, yang merepresentasikan biaya minimal yang tidak dapat dihindari dalam menyelesaikan rute TSP.

Matriks hasil reduksi akan memiliki setidaknya satu nilai 0 pada setiap baris dan kolom, sehingga mencerminkan pilihan minimal yang tersedia bagi algoritma pada tahap pencarian berikutnya. Nilai reduction cost ditambahkan pada biaya edge yang dipilih selama branching untuk menghasilkan estimasi batas bawah yang ketat. Jika batas bawah ini melebihi biaya terbaik saat ini, maka cabang tersebut dapat dipangkas tanpa eksplorasi lebih lanjut.

# **Backtracking**
"""

def tsp_backtracking(dist, start=0, time_limit=None, max_nodes_explore=None):
    n = dist.shape[0]
    visited = [False] * n

    best_cost = float('inf')
    best_route = None

    nodes_explored = 0
    pruned_count = 0
    iteration_best_found = None

    start_time = time.perf_counter()
    cutoff = False

    process = psutil.Process(os.getpid())
    peak_memory = 0.0

    visited[start] = True

    # MEOS: minimal outgoing edge
    min_out = np.min(np.where(np.isfinite(dist), dist, np.inf), axis=1)
    min_out[~np.isfinite(min_out)] = 0

    def dfs(current, depth, cost, path):
        nonlocal best_cost, best_route, nodes_explored, pruned_count
        nonlocal cutoff, iteration_best_found, peak_memory

        # peak memory
        current_memory = process.memory_info().rss / (1024 * 1024)  # MB
        peak_memory = max(peak_memory, current_memory)

        # cutoff
        if time_limit and (time.perf_counter() - start_time) > time_limit:
            cutoff = True
            return
        if max_nodes_explore and nodes_explored >= max_nodes_explore:
            cutoff = True
            return

        nodes_explored += 1

        # bound MEOS
        unvisited = np.where(~np.array(visited))[0]
        est_lower = cost + np.sum(min_out[unvisited])
        if est_lower >= best_cost:
            pruned_count += 1
            return

        # complete
        if depth == n:
            total_cost = cost + dist[current, start]
            if total_cost < best_cost:
                best_cost = total_cost
                best_route = path + [start]
                iteration_best_found = nodes_explored
            return

        for nxt in range(n):
            if (not visited[nxt]) and np.isfinite(dist[current, nxt]):
                visited[nxt] = True
                dfs(nxt, depth + 1, cost + dist[current, nxt], path + [nxt])
                visited[nxt] = False
                if cutoff:
                    return

    dfs(start, 1, 0.0, [start])

    return {
        "best_cost": best_cost,
        "best_route": best_route,
        "nodes_explored": nodes_explored,
        "pruned_count": pruned_count,
        "iteration_best_found": iteration_best_found,
        "runtime_s": time.perf_counter() - start_time,
        "cutoff": cutoff,
        "peak_memory_mb": peak_memory
    }

"""Algoritma Backtracking TSP yang digunakan pada penelitian ini bekerja dengan melakukan pencarian secara depth-first search (DFS) terhadap seluruh kemungkinan urutan kunjungan node. Untuk mengurangi jumlah cabang yang dieksplorasi, diterapkan teknik pruning berbasis MEOS (Minimal Edge Outgoing Sum). Nilai MEOS dihitung sebagai penjumlahan dari biaya minimum outgoing edge pada setiap node yang belum dikunjungi. Nilai ini ditambahkan ke biaya rute sementara sebagai lower bound estimasi biaya total. Jika lower bound tersebut sudah lebih besar atau sama dengan biaya rute terbaik yang telah ditemukan, maka cabang tersebut dipangkas karena tidak mungkin menghasilkan solusi yang lebih baik. Dengan cara ini, algoritma tetap menjamin solusi optimal (exact), tetapi dengan jumlah eksplorasi node yang jauh lebih sedikit dibandingkan backtracking brute force murni.

# **Branch and Bound**
"""

def branch_and_bound_tsp(dist, start=0, time_limit=None):
    n = dist.shape[0]

    # --- root node ---
    root = dist.copy()
    np.fill_diagonal(root, np.inf)
    root, root_lb = reduce_matrix(root)

    visited0 = [False] * n
    visited0[start] = True

    heap = []
    # (bound, curr, level, path, visited, reduced_matrix, lb_cost, true_cost)
    heapq.heappush(
        heap,
        (root_lb, start, 1, [start], visited0, root, root_lb, 0.0)
    )

    best_cost = float('inf')
    best_route = None

    nodes_expanded = 0
    pruned_count = 0
    generated_children = 0
    iteration_best_found = None
    max_queue_size = 1

    start_time = time.perf_counter()
    cutoff = False

    process = psutil.Process(os.getpid())
    peak_memory = 0.0

    while heap:
        # peak memory
        current_memory = process.memory_info().rss / (1024 * 1024)
        peak_memory = max(peak_memory, current_memory)

        if time_limit and (time.perf_counter() - start_time) > time_limit:
            cutoff = True
            break

        bound, curr, level, path, visited, red_mat, lb_cost, true_cost = heapq.heappop(heap)
        nodes_expanded += 1
        max_queue_size = max(max_queue_size, len(heap) + 1)

        # pruning by bound
        if bound >= best_cost:
            pruned_count += 1
            continue

        # complete tour
        if level == n:
            total_cost = true_cost + dist[curr, start]
            if total_cost < best_cost:
                best_cost = total_cost
                best_route = path + [start]
                iteration_best_found = nodes_expanded
            continue

        # expand children
        for j in range(n):
            if visited[j] or not np.isfinite(dist[curr, j]):
                continue

            generated_children += 1

            child_visited = visited.copy()
            child_visited[j] = True

            child_mat = red_mat.copy()
            child_mat[curr, :] = np.inf
            child_mat[:, j] = np.inf
            child_mat[j, start] = np.inf

            child_mat, red_cost = reduce_matrix(child_mat)
            new_bound = lb_cost + red_mat[curr, j] + red_cost

            if new_bound < best_cost:
                heapq.heappush(
                    heap,
                    (
                        new_bound,
                        j,
                        level + 1,
                        path + [j],
                        child_visited,
                        child_mat,
                        new_bound,
                        true_cost + dist[curr, j]
                    )
                )
            else:
                pruned_count += 1

    return {
        "best_cost": best_cost,
        "best_route": best_route,
        "nodes_expanded": nodes_expanded,
        "generated_children": generated_children,
        "pruned_count": pruned_count,
        "iteration_best_found": iteration_best_found,
        "max_queue_size": max_queue_size,
        "runtime_s": time.perf_counter() - start_time,
        "cutoff": cutoff,
        "peak_memory_mb": peak_memory
    }

"""Algoritma Branch and Bound TSP pada penelitian ini merepresentasikan setiap state pencarian sebagai sebuah node dalam pohon pencarian yang disimpan di dalam priority queue (min-heap). Setiap node menyimpan informasi berupa rute parsial, biaya aktual (true cost), matriks jarak yang telah direduksi, serta nilai lower bound yang dihitung melalui operasi reduksi baris dan kolom. Pada setiap langkah, algoritma selalu mengekspansi node dengan nilai bound terkecil terlebih dahulu. Untuk setiap perluasan rute dari suatu node ke node berikutnya, matriks jarak dimodifikasi dengan melarang kunjungan ulang ke node yang sama dan mencegah terbentuknya subtour, kemudian direduksi kembali untuk menghasilkan lower bound baru. Jika bound suatu node melebihi biaya solusi terbaik sementara, node tersebut dipangkas (pruned). Proses ini berlanjut hingga seluruh kemungkinan rute yang menjanjikan telah dieksplorasi, sehingga diperoleh solusi TSP yang optimal dengan jumlah ekspansi node yang jauh lebih sedikit dibandingkan eksplorasi brute force.

# **Perbandingan Backtracking vs Branch and Bound**
"""

PRINT_DEMO_ONLY = True

for sz in sizes_to_test:
    if sz > N_ALL:
        print(f"\n[WARNING] n={sz} > jumlah node ({N_ALL}), dilewati.")
        continue

    set_seed(BASE_SEED + sz)
    indices = np.random.choice(np.arange(N_ALL), size=sz, replace=False).tolist()
    sub_names = [names_all[i] for i in indices]
    sub_dist = dist_matrix[np.ix_(indices, indices)]

    print(f"\n=====================================")
    print(f"=== EKSPERIMEN UNTUK n = {sz} NODE ===")
    print("=====================================")

    for r in range(REPEATS):
        run_seed = BASE_SEED + sz * 1000 + r
        set_seed(run_seed)

        # ---------------------- Branch & Bound ----------------------
        if (not PRINT_DEMO_ONLY) or (r == 0):
            print("\n[Branch & Bound] Running...")

        bnb_res = branch_and_bound_tsp(sub_dist, start=0, time_limit=time_limit_per_run)

        bnb_route_idx = bnb_res["best_route"]
        bnb_route_names = [sub_names[i] for i in bnb_route_idx] if bnb_route_idx else None

        if (not PRINT_DEMO_ONLY) or (r == 0):
            print(f"[Branch & Bound] Hasil:")
            print(f"  - Biaya terbaik (meter)      : {bnb_res['best_cost']:.2f}")
            print(f"  - Runtime (detik)            : {bnb_res['runtime_s']:.4f}")
            print(f"  - Nodes expanded             : {bnb_res['nodes_expanded']}")
            print(f"  - Iteration best found       : {bnb_res['iteration_best_found']}")
            print(f"  - Pruned count               : {bnb_res['pruned_count']}")
            print(f"  - Generated children         : {bnb_res['generated_children']}")
            print(f"  - Max queue size             : {bnb_res['max_queue_size']}")
            print(f"  - Cutoff                     : {bnb_res['cutoff']}")
            print(f"  - Rute (index)               : {bnb_route_idx}")
            print(f"  - Rute (nama tempat)         : {bnb_route_names}")
            print(f"  - Peak Memory (MB)           : {bnb_res['peak_memory_mb']:.2f}") # Added peak memory print

        results.append({
            "experiment_id": experiment_id,
            "n": sz,
            "repeat": r,
            "seed": run_seed,
            "algorithm": "branch_and_bound",
            "best_cost_m": float(bnb_res["best_cost"]),
            "best_route_idx": bnb_route_idx,
            "best_route_names": bnb_route_names,
            "runtime_s": float(bnb_res["runtime_s"]),
            "nodes_expanded": int(bnb_res["nodes_expanded"]),
            "iteration_best_found": bnb_res["iteration_best_found"],
            "pruned_count": int(bnb_res["pruned_count"]),
            "generated_children": int(bnb_res["generated_children"]),
            "max_queue_size": int(bnb_res["max_queue_size"]),
            "cutoff": bool(bnb_res["cutoff"]),
            "timeout_s": time_limit_per_run,
            "nodes": ";".join(sub_names),
            "peak_memory_mb": float(bnb_res["peak_memory_mb"])
        })

        # ---------------------- Backtracking ------------------------
        if sz <= max_backtracking_n:
            if (not PRINT_DEMO_ONLY) or (r == 0):
                print("\n[Backtracking] Running...")

            bt_res = tsp_backtracking(sub_dist, start=0, time_limit=time_limit_per_run, max_nodes_explore=BT_NODE_LIMIT)

            bt_route_idx = bt_res["best_route"]
            bt_route_names = [sub_names[i] for i in bt_route_idx] if bt_route_idx else None

            if (not PRINT_DEMO_ONLY) or (r == 0):
                print(f"[Backtracking] Hasil:")
                print(f"  - Biaya terbaik (meter)      : {bt_res['best_cost']:.2f}")
                print(f"  - Runtime (detik)            : {bt_res['runtime_s']:.4f}")
                print(f"  - Nodes explored             : {bt_res['nodes_explored']}")
                print(f"  - Iteration best found       : {bt_res['iteration_best_found']}")
                print(f"  - Pruned count               : {bt_res['pruned_count']}")
                print(f"  - Cutoff                     : {bt_res['cutoff']}")
                print(f"  - Rute (index)               : {bt_route_idx}")
                print(f"  - Rute (nama tempat)         : {bt_route_names}")
                print(f"  - Peak Memory (MB)           : {bt_res['peak_memory_mb']:.2f}") # Added peak memory print

            results.append({
                "experiment_id": experiment_id,
                "n": sz,
                "repeat": r,
                "seed": run_seed,
                "algorithm": "backtracking",
                "best_cost_m": float(bt_res["best_cost"]),
                "best_route_idx": bt_route_idx,
                "best_route_names": bt_route_names,
                "runtime_s": float(bt_res["runtime_s"]),
                "nodes_explored": int(bt_res["nodes_explored"]),
                "iteration_best_found": bt_res["iteration_best_found"],
                "pruned_count": int(bt_res["pruned_count"]),
                "cutoff": bool(bt_res["cutoff"]),
                "timeout_s": time_limit_per_run,
                "max_nodes_explore_limit": BT_NODE_LIMIT,
                "nodes": ";".join(sub_names),
                "peak_memory_mb": float(bt_res["peak_memory_mb"]) # Added peak memory to results
            })
        else:
            if (not PRINT_DEMO_ONLY) or (r == 0):
                print(f"\n[Backtracking] Dilewati untuk n={sz} (dianggap tidak feasible).")

        if PRINT_DEMO_ONLY:
            break

"""# **Ringkasan Hasil Perbandingan**"""

import pandas as pd

if 'results' not in globals() or not results:
    raise RuntimeError("results belum ada. Jalankan cell eksperimen dulu.")

Results_df = pd.DataFrame(results)

df_raw = Results_df.copy()

df_raw['nodes_expanded'] = df_raw['nodes_expanded'].fillna(0)
df_raw['nodes_explored'] = df_raw['nodes_explored'].fillna(0)
df_raw['max_queue_size'] = df_raw['max_queue_size'].fillna(0)
df_raw['generated_children'] = df_raw['generated_children'].fillna(0)
df_raw['pruned_count'] = df_raw['pruned_count'].fillna(0)

if 'peak_memory_mb' in df_raw.columns:
    df_raw['peak_memory_mb'] = df_raw['peak_memory_mb'].fillna(0)
else:
    df_raw['peak_memory_mb'] = 0.0

df_raw['n'] = df_raw['n'].astype(int)
df_raw['runtime_s'] = df_raw['runtime_s'].astype(float)
df_raw['best_cost_m'] = df_raw['best_cost_m'].astype(float)
df_raw['cutoff'] = df_raw['cutoff'].astype(bool)
df_raw['nodes_expanded'] = df_raw['nodes_expanded'].astype(float)
df_raw['nodes_explored'] = df_raw['nodes_explored'].astype(float)
df_raw['pruned_count'] = df_raw['pruned_count'].astype(float)
df_raw['generated_children'] = df_raw['generated_children'].astype(float)
df_raw['max_queue_size'] = df_raw['max_queue_size'].astype(float)
df_raw['peak_memory_mb'] = df_raw['peak_memory_mb'].astype(float)

summary_rows = []

for (n_val, algo), group in df_raw.groupby(['n', 'algorithm']):
    row = {'n': n_val, 'algorithm': algo}

    m, s, ci_low, ci_high = summarize(group['runtime_s'].tolist())
    row['runtime_mean_s'] = m
    row['runtime_std_s'] = s
    row['runtime_CI95_low_s'] = ci_low
    row['runtime_CI95_high_s'] = ci_high

    if algo == 'branch_and_bound':
        m_nodes, s_nodes, ci_low_nodes, ci_high_nodes = summarize(group['nodes_expanded'].tolist())
    else:
        m_nodes, s_nodes, ci_low_nodes, ci_high_nodes = summarize(group['nodes_explored'].tolist())
    row['nodes_mean'] = m_nodes
    row['nodes_std'] = s_nodes
    row['nodes_CI95_low_s'] = ci_low_nodes
    row['nodes_CI95_high_s'] = ci_high_nodes

    if 'peak_memory_mb' in group.columns:
        m_mem, s_mem, ci_low_mem, ci_high_mem = summarize(group['peak_memory_mb'].tolist())
        row['peakmem_mean_mb'] = m_mem
        row['peakmem_std_mb'] = s_mem
        row['peakmem_CI95_low_mb'] = ci_low_mem
        row['peakmem_CI95_high_mb'] = ci_high_mem
    else:
        row['peakmem_mean_mb'] = 0.0
        row['peakmem_std_mb'] = 0.0
        row['peakmem_CI95_low_mb'] = 0.0
        row['peakmem_CI95_high_mb'] = 0.0

    row['cutoff_rate'] = group['cutoff'].mean()

    valid_costs = group[~group['cutoff']]['best_cost_m']
    if not valid_costs.empty:
        row['best_cost_min_m'] = valid_costs.min()
    else:
        row['best_cost_min_m'] = float('inf')

    summary_rows.append(row)

df_summary = pd.DataFrame(summary_rows)

print("\n==================== RINGKASAN HASIL EKSPERIMEN ====================")
display(df_summary)

print("\n==================== DETAIL RUTE (TERCEPAT per n,algoritma) ====================")

best_rows = (
    Results_df.sort_values(["n","algorithm","runtime_s"])
    .groupby(["n","algorithm"], as_index=False)
    .head(1)
)

for _, row in best_rows.iterrows():
    print(f"\n[Experiment] n={row['n']}, algorithm={row['algorithm']}")
    print(f"  - Biaya terbaik (meter): {row['best_cost_m']:.2f}")
    print(f"  - Waktu eksekusi (detik): {row['runtime_s']:.4f}")
    print(f"  - Cutoff               : {row['cutoff']}")
    print(f"  - Rute                 : {row['best_route_names']}")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

if 'results' not in globals():
    print("Error: The 'results' list is not defined. Please ensure the experiment cell (e.g., cell '5R4R9B2fVUSi') has been executed successfully before running this cell.")
    results_df = pd.DataFrame()
    df = pd.DataFrame()
else:
    if 'results_df' not in globals() or results_df.empty:
        results_df = pd.DataFrame(results)

    df = results_df.copy()

    df = df.fillna(0)

    df['max_queue_size'] = df['max_queue_size'].astype(int)
    df['max_nodes_explore_limit'] = df['max_nodes_explore_limit'].astype(int)
    df["n"] = df["n"].astype(int)
    df["runtime_s"] = df["runtime_s"].astype(float)
    df["best_cost_m"] = df["best_cost_m"].astype(float)
    df["cutoff"] = df["cutoff"].astype(bool)

    df["runtime_ms"] = df["runtime_s"] * 1000.0

    display(df.head(6))

"""# **Visualisasi**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ====== PILIH DATAFRAME ======
# recommended:
df = df.copy()

# runtime_ms
df["runtime_ms"] = df["runtime_s"].astype(float) * 1000.0

mean_time = (
    df.groupby(["n", "algorithm"], as_index=False)["runtime_ms"]
      .mean()
      .rename(columns={"runtime_ms": "mean_runtime_ms"})
)

plt.figure()
for algo in mean_time["algorithm"].unique():
    tmp = mean_time[mean_time["algorithm"] == algo].sort_values("n")
    plt.plot(tmp["n"], tmp["mean_runtime_ms"], marker="o", label=algo)

plt.xlabel("n (jumlah node)")
plt.ylabel("Mean runtime (ms)")
plt.title("n vs Mean Runtime (ms) per Algoritma")
plt.legend()
plt.grid(True)
plt.show()

plt.figure()

algos = sorted(df["algorithm"].unique())
data = [df[df["algorithm"] == a]["runtime_ms"].values for a in algos]

plt.boxplot(data, labels=algos, showfliers=True)
plt.xlabel("Algoritma")
plt.ylabel("Runtime (ms)")
plt.title("Boxplot Runtime per Algoritma")
plt.grid(True, axis="y")
plt.show()

plot_order = ["branch_and_bound", "backtracking"]  # backtracking terakhir = paling depan

plt.figure()
markers = {"branch_and_bound": "o", "backtracking": "s"}

for algo in plot_order:
    tmp = gap_plot[gap_plot["algorithm"] == algo].sort_values("n")
    if not tmp.empty:
        plt.plot(tmp["n"], tmp["gap_percent"], marker=markers.get(algo, "o"), label=algo)

plt.xlabel("n (jumlah node)")
plt.ylabel("Mean gap (%)")
plt.title("Gap (%) vs n per Algoritma")
plt.legend()
plt.grid(True)
plt.xticks(sorted(df["n"].unique()))
plt.show()

agg_rows = []

for (nval, algo), g in df.groupby(["n", "algorithm"]):
    row = {"n": int(nval), "algorithm": algo}

    if algo == "backtracking" and "nodes_explored" in g.columns:
        vals = g["nodes_explored"].replace(0, np.nan).dropna().astype(float)
        row["mean_nodes"] = vals.mean()
        row["std_nodes"] = vals.std(ddof=1) if len(vals) > 1 else 0.0

    if algo == "branch_and_bound" and "nodes_expanded" in g.columns:
        vals = g["nodes_expanded"].replace(0, np.nan).dropna().astype(float)
        row["mean_nodes"] = vals.mean()
        row["std_nodes"] = vals.std(ddof=1) if len(vals) > 1 else 0.0

    agg_rows.append(row)

aggregated_df = pd.DataFrame(agg_rows).sort_values(["n", "algorithm"]).reset_index(drop=True)
display(aggregated_df)

plt.figure(figsize=(10, 6))

markers = {"branch_and_bound": "o", "backtracking": "s"}
plot_order = ["branch_and_bound", "backtracking"]

for algo in plot_order:
    tmp = aggregated_df[aggregated_df["algorithm"] == algo].sort_values("n")
    if tmp.empty:
        continue

    x = tmp["n"].values
    y = tmp["mean_nodes"].values
    yerr = tmp["std_nodes"].values

    plt.errorbar(
        x, y, yerr=yerr,
        marker=markers.get(algo, "o"),
        linestyle='-',
        capsize=4,
        label=f"{algo} (mean ± std)"
    )

plt.xlabel("n (jumlah node)")
plt.ylabel("Rata-rata Nodes (Explored/Expanded) ± StdDev")
plt.title("Rata-rata Node Dieksplorasi/Diekspansi per Algoritma")
plt.legend()
plt.grid(True)
plt.xticks(sorted(aggregated_df["n"].unique()))

# Log scale biar kebaca kalau beda jauh (hanya jika semua > 0)
y_all = aggregated_df["mean_nodes"].dropna().values
if len(y_all) and np.all(y_all > 0):
    plt.yscale("log")

plt.show()

"""## Summary:

### Data Analysis Key Findings
*   The `aggregated_df` was successfully generated, presenting the mean and standard deviation of nodes explored (for backtracking) or expanded (for branch\_and\_bound) for various `n` values and algorithms.
*   A plot was successfully created and displayed, visualizing the "Rata-rata Node Dieksplorasi/Diekspansi per Algoritma" (Average Nodes Explored/Expanded per Algorithm). This plot shows the mean number of nodes along with their standard deviation against `n`, with a logarithmic y-axis applied if all mean values are positive.

### Insights or Next Steps
*   The generated plot now allows for a direct comparison of the average number of nodes explored/expanded between the "backtracking" and "branch\_and\_bound" algorithms across different problem sizes (`n`).
*   Further analysis could involve interpreting the trends shown in the plot to determine which algorithm performs more efficiently in terms of node exploration/expansion for different `n` values.

"""